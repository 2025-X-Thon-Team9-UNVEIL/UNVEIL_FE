import { useState, useRef, useEffect } from 'react';
import RecordRTC from 'recordrtc';
import axios from 'axios'; // ë˜ëŠ” ì‚¬ìš© ì¤‘ì¸ axiosInstance
import bad_audio from '@/assets/audio/test_bad_room.wav';
import good_audio from '@/assets/audio/test_good_room.wav';
import normal_audio from '@/assets/audio/test_normal_room.wav';
import test_audio from '@/assets/audio/measurement_signal_5s.wav';
import speakerIcon from '@/assets/icon-speaker.svg';
import { useLocation, useNavigate } from 'react-router-dom';
import arrowIcon from '@/assets/icon-arrow-left.svg';

// ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•œ ì»´í¬ë„ŒíŠ¸ë“¤ (ê°€ì •)
// import Header from '@/components/Header';
// import Button from '@/components/Button';
interface RecordProps {
  onAnalysisComplete: (rank: string) => void;
}

const Record = ({ onAnalysisComplete }: RecordProps) => {
  const show_download = false; // ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ ì—¬ë¶€ ì¡°ì ˆìš© í”Œë˜ê·¸

  // ğŸ”Š [ì¶”ê°€] ë…¹ìŒëœ ì˜¤ë””ì˜¤ URLì„ ì €ì¥í•  state
  const [audioUrl, setAudioUrl] = useState<string | null>(null);

  const [isRecording, setIsRecording] = useState(false);
  const [timer, setTimer] = useState('00:00.00');
  const [status, setStatus] = useState('ì¸¡ì • ëŒ€ê¸° ì¤‘');

  // ë ˆí¼ëŸ°ìŠ¤ ì„¤ì •
  const recorderRef = useRef<RecordRTC | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const startTimeRef = useRef<number>(0);
  const timerIntervalRef = useRef<number | null>(null);

  // ğŸ”Š í…ŒìŠ¤íŠ¸ìš© ì‚¬ìš´ë“œ íŒŒì¼ ë¡œë“œ (ê²½ë¡œëŠ” ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ì— ë§ê²Œ ìˆ˜ì •)
  const testAudio = useRef(new Audio(test_audio));

  // íƒ€ì´ë¨¸ ë¡œì§
  const startTimer = () => {
    startTimeRef.current = Date.now();
    timerIntervalRef.current = window.setInterval(() => {
      const now = Date.now();
      const diff = now - startTimeRef.current;

      const minutes = Math.floor(diff / 60000);
      const seconds = Math.floor((diff % 60000) / 1000);
      const milliseconds = Math.floor((diff % 1000) / 10);

      setTimer(
        `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}.${milliseconds.toString().padStart(2, '0')}`,
      );
    }, 10);
  };

  const stopTimer = () => {
    if (timerIntervalRef.current) {
      clearInterval(timerIntervalRef.current);
      setTimer('00:00.00');
    }
  };

  // ğŸ¤ ë…¹ìŒ ì‹œì‘ í•¸ë“¤ëŸ¬
  const handleStartRecording = async () => {
    try {
      setStatus('ë§ˆì´í¬ ì´ˆê¸°í™” ì¤‘...');

      // 1. ë§ˆì´í¬ ê¶Œí•œ íšë“ (ë°˜í–¥ ë¶„ì„ì„ ìœ„í•œ í•µì‹¬ ì„¤ì •)
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false, // ğŸ”¥ í•„ìˆ˜: ì—ì½” ìº”ìŠ¬ë§ ë” (ë°˜í–¥ ë…¹ìŒ ìœ„í•´)
          noiseSuppression: false, // ğŸ”¥ í•„ìˆ˜: ì¡ìŒ ì œê±° ë”
          autoGainControl: false, // ğŸ”¥ í•„ìˆ˜: ìë™ ë³¼ë¥¨ ì¡°ì ˆ ë”
          sampleRate: 44100, // ê³ ìŒì§ˆ (ì¼ë¶€ ëª¨ë°”ì¼ í˜¸í™˜ì„± ìœ„í•´ ìƒëµ ê°€ëŠ¥)
        },
      });

      streamRef.current = stream;

      // 2. RecordRTC ì„¤ì • (WAV í¬ë§·)
      recorderRef.current = new RecordRTC(stream, {
        type: 'audio',
        mimeType: 'audio/wav',
        recorderType: RecordRTC.StereoAudioRecorder, // WAV ìƒì„±ì„ ìœ„í•œ ì„¤ì •
        numberOfAudioChannels: 1, // ë¶„ì„ìš©ì€ ëª¨ë…¸(1)ë¡œ ì¶©ë¶„ (ìš©ëŸ‰ ì ˆì•½)
        desiredSampRate: 44100, // CD ìŒì§ˆ
      });

      // 3. ë…¹ìŒ ì‹œì‘
      recorderRef.current.startRecording();
      startTimer();
      setIsRecording(true);
      setStatus('ë…¹ìŒ ì¤‘... ì†Œë¦¬ê°€ ì¬ìƒë©ë‹ˆë‹¤.');
      console.log('ë§ˆì´í¬ ê¶Œí•œ íšë“ ë° ë…¹ìŒ ì‹œì‘');

      // 4. 0.5ì´ˆ ë’¤ í…ŒìŠ¤íŠ¸ ì‚¬ìš´ë“œ ì¬ìƒ (ë…¹ìŒê¸°ê°€ ì¼œì§„ í›„ ì†Œë¦¬ê°€ ë‚˜ì•¼ í•¨)
      setTimeout(() => {
        testAudio.current.play().catch((e) => console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨', e));
      }, 500);
      console.log('ë…¹ìŒ ì‹œì‘');
    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error);
      setStatus('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
    }
  };

  // â¹ï¸ ë…¹ìŒ ì¢…ë£Œ ë° ì „ì†¡ í•¸ë“¤ëŸ¬
  const handleStopRecording = () => {
    if (!recorderRef.current) return;

    setStatus('ë…¹ìŒ ì¢…ë£Œ. íŒŒì¼ ë³€í™˜ ì¤‘...');
    stopTimer();
    setIsRecording(false);

    // ë…¹ìŒ ì¤‘ì§€
    recorderRef.current.stopRecording(() => {
      // 1. Blob ì¶”ì¶œ (WAV í˜•ì‹)
      const blob = recorderRef.current!.getBlob();

      // 2. File ê°ì²´ë¡œ ë³€í™˜
      const file = new File([blob], 'room_acoustics.wav', { type: 'audio/wav' });

      // ==========================================================
      // ğŸ‘‡ [í•µì‹¬] ë°±ì—”ë“œ ì „ì†¡ ëŒ€ì‹ , ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ í™•ì¸í•˜ëŠ” ë¡œì§
      // ==========================================================

      // 1. ë¸Œë¼ìš°ì €ì—ì„œ ì¬ìƒ ê°€ëŠ¥í•œ URL ìƒì„±
      const url = URL.createObjectURL(blob);
      setAudioUrl(url); // stateì— ì €ì¥í•´ì„œ UIì— í‘œì‹œ

      console.log(`íŒŒì¼ ìƒì„± ì™„ë£Œ: ${file.size} bytes`);

      // 2. ì½˜ì†”ì— íŒŒì¼ ì •ë³´ ì¶œë ¥ (WAVì¸ì§€, ìš©ëŸ‰ì´ ì¡íˆëŠ”ì§€ í™•ì¸)
      console.log('=== ë…¹ìŒ íŒŒì¼ ì •ë³´ ===');
      console.log('íŒŒì¼ëª…:', file.name);
      console.log('íŒŒì¼ íƒ€ì…:', file.type); // 'audio/wav' ì—¬ì•¼ í•¨
      console.log('íŒŒì¼ í¬ê¸°:', file.size, 'bytes'); // 0ì´ë©´ ë…¹ìŒ ì•ˆ ëœ ê²ƒ

      // 3. ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ (ë§ˆì´í¬ ë„ê¸°)
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }

      // 4. ë°±ì—”ë“œ ì „ì†¡
      sendToBackend(file);
    });
  };

  // ğŸš€ ë°±ì—”ë“œ ì „ì†¡ í•¨ìˆ˜
  const sendToBackend = async (file: File) => {
    setStatus('ì„œë²„ë¡œ ì „ì†¡ ì¤‘...');

    const formData = new FormData();
    formData.append('body', file); // ë°±ì—”ë“œì—ì„œ ë°›ì„ í‚¤ ì´ë¦„ ('file')

    try {
      // ì‹¤ì œ API ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”
      const response = await axios.post(
        'https://port-0-unveil-ai-mia4sbpyf7bf2574.sel3.cloudtype.app/api/noise',
        formData,
        {
          headers: { 'Content-Type': 'multipart/form-data' },
        },
      );

      console.log('ì—…ë¡œë“œ ì„±ê³µ:', response.data);
    const resultRank = response.data.result.grade;
      console.log('ë“±ê¸‰:', resultRank);
        onAnalysisComplete(resultRank); // ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ì— ë“±ê¸‰ ì „ë‹¬
      setStatus('ë¶„ì„ ì™„ë£Œ!');
    } catch (error) {
      console.error('ì—…ë¡œë“œ ì‹¤íŒ¨:', error);
      setStatus('ì „ì†¡ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    }
  };

  return (
    <div className="flex flex-col h-screen bg-white">
      <main className="flex flex-col items-center  flex-1 px-6">
        {/* íƒ€ì´ë¨¸ */}
        <div className="text-gray-400 text-xl font-mono mb-10">{timer}</div>

        {/* íŒŒí˜• ë¹„ì£¼ì–¼ë¼ì´ì € (ë”ë¯¸ UI - ì‹¤ì œ ì—°ë™í•˜ë ¤ë©´ Canvas í•„ìš”) */}
        <div className="w-full h-12 flex items-center justify-center gap-1 mb-20 overflow-hidden">
          {isRecording ? (
            /* ë…¹ìŒ ì¤‘ì¼ ë•Œ ì›€ì§ì´ëŠ” ì• ë‹ˆë©”ì´ì…˜ (CSSë¡œ êµ¬í˜„ ê°€ëŠ¥) */
            Array.from({ length: 30 }).map((_, i) => (
              <div key={i} className="w-1 bg-red-400 animate-pulse" style={{ height: `${Math.random() * 100}%` }}></div>
            ))
          ) : (
            /* ëŒ€ê¸° ìƒíƒœ ì ì„  */
            <div className="text-red-300 tracking-widest">................................</div>
          )}
        </div>

        {/* ë…¹ìŒ ë²„íŠ¼ */}
        <button
          onClick={isRecording ? handleStopRecording : handleStartRecording}
          className={`w-20 h-20 rounded-full border-4 flex items-center justify-center transition-all ${
            isRecording ? 'border-gray-300 bg-white' : 'border-gray-300 bg-white'
          }`}>
          <div
            className={`rounded transition-all ${
              isRecording
                ? 'w-8 h-8 bg-red-500 rounded-sm' // ì •ì§€ ì•„ì´ì½˜ (ë„¤ëª¨)
                : 'w-10 h-10 bg-red-500 rounded-full' // ë…¹ìŒ ì•„ì´ì½˜ (ì›)
            }`}
          />
        </button>
        <p className="mt-4 text-gray-500 text-sm">{status}</p>

        {/* ğŸ‘‡ [ì¶”ê°€] ë…¹ìŒì´ ëë‚˜ë©´ ë‚˜íƒ€ë‚˜ëŠ” í™•ì¸ìš© í”Œë ˆì´ì–´ & ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ */}
        {show_download && audioUrl && (
          <div className="mt-8 p-4 border border-gray-300 rounded-lg bg-gray-50 flex flex-col items-center gap-4">
            <p className="font-bold text-sm text-gray-600">ë…¹ìŒ ê²°ê³¼ í™•ì¸ (ë°±ì—”ë“œ ì „ì†¡ ì „)</p>

            {/* 1. ë°”ë¡œ ë“¤ì–´ë³´ê¸° */}
            <audio src={audioUrl} controls className="w-60" />

            {/* ğŸ‘‡ ìƒˆ íƒ­ì—ì„œ ì—´ê¸° ë²„íŠ¼ */}
            <button
              className="text-blue-500 underline text-sm"
              onClick={() => {
                const newWindow = window.open(audioUrl, '_blank');
                if (!newWindow) alert('íŒì—…ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
              }}>
              WAV íŒŒì¼ ìƒˆ íƒ­ì—ì„œ ì—´ê¸°
            </button>

            {/* 2. ë‚´ ì»´í“¨í„°/í°ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ì„œ í™•ì¸í•˜ê¸° */}
            <a href={audioUrl} download="room_acoustics.wav" className="text-blue-500 underline text-sm">
              WAV íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            </a>
          </div>
        )}
      </main>
    </div>
  );
};

export default Record;
